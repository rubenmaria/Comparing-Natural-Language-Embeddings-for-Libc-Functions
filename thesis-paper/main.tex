\documentclass[12pt,letterpaper]{article}
\input{settings}
\usepackage{mathtools}
\usepackage{amssymb}

\begin{document}
\newcommand{\nat}[0]{\mathbf{N}}
\selectlanguage{german}


\begin{center}\uppercase{Ludwig-Maximilians-Universität München}\end{center}
\begin{center}
  \uppercase{Programming languages and artificial intelligence}
\end{center}

\vspace*{10mm}
\begin{center}
\includegraphics[height=40mm]{sigillum.png}
\end{center}
\vspace*{10mm}

\title{Titel der Arbeit}
\date{\vspace{-5ex}}
{\let\newpage\relax\maketitle}
\thispagestyle{empty}
\begin{center}
\begin{large}
\begin{Large}
Bachelorarbeit\\
\end{Large}
im Studiengang 'Informatik plus Mathematik' \\
\end{large}
\end{center}
\vspace{1cm}
\begin{center}
\begin{large}
Betreuer: Prof. Dr. Johannes Kinder\\
\end{large}
\end{center}
\begin{center}
\begin{large}
Mentor: Moritz Dannehl, M.Sc.\\
\end{large}
\end{center}


\begin{center}
\begin{large}
Ablieferungstermin: \date{\today} \\
\end{large}
\end{center}

\vspace{1,5cm}

\newpage
\tableofcontents
\newpage

\setcounter{page}{1}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0pt} %obere Trennlinie
\newtheorem{definition}{Definition}
\section*{Abstract}
\section{Einführung}
In den letzten Jahren gab es große Fortschritte in der natürlichen
Sprachverarbeitung, besonders hervorzuheben sind Large Language Models
die sich mittlerweile in vielen Bereichen der Informatik in die Lösungsansätze
für Problemen in jeweiligen Bereichen eingeschlichen haben. Diese Arbeit
untersucht nun, ob diese Fortschritte in der natürlichen Sprachverarbeitung
eine Hilfestellung leisten können um Source Code Funktionen semantisch sinvoll
in einen Vektor mit reelwertigen Zahlen zu codieren. Diese Vektoren können dann
später als Label verwendet werden um ein Modell zu trainieren was Binary Code 
als Input nimmt und diesen ebenfalls in einen semantischen Vektor mit reelwertigen
Zahlen codiert. Das resultierende Modell kann hinterher verwendet werden um Reverse 
Engeneering zu erleichtern. Ein einfaches Beispiel ist folgendes: Man stelle
sich vor, dass man eine Funktion die in Binary Code vorliegt, mühsehlig manuell
verstanden was für eine Aufgabe die Funktion in der Code Base hat. Nun kann man
diese Funktion codieren und über die Gesamte Code Base einen Nearest Neighbor
Search durchführen und all ähnlichen Funktionen ausgeben lassen.
Das spart zeit, denn nun hat man eine Idee was diese anderen
Funktionen für eine Aufgabe in der Code Base erfüllen könnten.\\
Das oben berschriebene Problem Source Code Vektoren in sinvoll semantische 
reelwertige Vektoren zu codieren ist sehr ähnlich zu einen Problem 
in der natürlichen Sprachverarbeitung und dort bereits gelöst. Die rede ist
von dem Problem einen gegebenen Satz in einen semantisch sinvollen Vektor
abzubilden. Es ist nageliegend zu versuchen dieses Ergebnis der natürlichen
Sprachverarbeitung zu benuzten um eine Lösung für unser Problem zu konstruieren.
Die intuivste Idee ist es einfach die Funktionsnamen, die in natürlicher Sprache
verfasst sind als beschreibung der Funktion zu verwenden. Diese Beschreibunf können
wir nun mühelos codieren, da sie in natürlicher Sprache vorliegt.
Eine zweite Idee ist, die Kommentare der Funktionen, die in natürlicher Sprache
verfasst sind, als Beschreibung der Funktion zu verwenden. Am viel versprechsten
ist es die Funktionen von einen Large Language Modell in natürlicher Sprache
beschreiben zu lassen. Als letztes habe ich noch ein bestehendes Modell
Code2Vec verwendet und es für dieses Problem angepasst.
\pagebreak
\section{Grundlagen und Termini}
\subsection{Maschienelles Lernen}
In diesen Abschnitt wird zunächst maschinelles lernen definiert und 
dann darauf aufbauend grundlegende Trainingsarten vorgestellt.
Heutzutage ist maschienelles Lernen weitverbreitet und wird nahezu in jeden
Bereich der Informatik verwendet. Maschinelles Lernen wird überall eingesetzt
wo eine anayltische Lösung eines Problems zu aufwendig oder gar überhauptnicht
existiert. % Book: Learingin from data, page 1, row 6
\subsubsection{Definition}
Diese Lösung durch maschinelles Lernen versucht aus den Daten ein Muster
abzuleiten. Bei einer endlichen Menge an Daten ist klar,
dass das resultierende Modell nur eine approximation der gesuchten Lösung
ist. Trotz des bekanntheitsgrades, gibt es den irreglauben, dass
maschinelles lernen nur was mit Neuronalen Netzwerken zu tun
hat, diese Anahme ist im allgemeinen falsch. Im folgenden wird eine 
allgeimeine Defintion von maschinellen Lernen vorgestellt:
\begin{definition}
  Sei $X$ eine beliebige Input Menge, $Y$ eine beliebige Output Menge,
  $f \in \{X \to Y\}$ die gesuchte Lösung des Problems, 
  $\mathbb{D}$ eine beliebige Menge aus gegebenen Datenpunkten,\\
  $H_1 \subset \{X \to Y\}$ ein Hypothesenraum, und 
  $A_1: \mathcal{P}(\{X \to Y\}) \times 
  \mathcal{P}(\mathbb{D}) \to \{ X \to Y \} $
  ein Lernalgorithmus. Dann ist das ziel, bei gegebenen Daten,
  den Hypothesenraum $H_1$ und den Lernalgorithmus $A_1$ so zu wählen,
  sodass
  \[
    A_1(H_1, \mathbb{D}) \approx f.
  \]
\end{definition}
Maschinelles lernen ist also die suche nach einen Lernalgorithmus und 
Hypothesenraum, die dann in kombination mit gegebenen Daten, die optimale
Lösung approximieren. Dabei ist hervorzuheben das der Datensatz das Herzstück
jeder Problemstellung im Bereich des maschinellen Lernens ist. Ist der 
Datensatz zu klein oder überhaupt nicht representativ für das gegebene
Probelm, wird der Lernalgorithmus die falschen Muster erkennen und dadurch
eine fehlerhafte approximation produzieren. % visualisierung.
\\


%learning from statistics
%Grundlegende Begriffe
\subsection{Sentence Transformer}
% Sentence Transformer Paper und ein wenig Geschichte
\subsection{Large Language Models}
% Large language Model paper und ein wenig Geschichte
\subsection{Code2Vec}
%\subsection{Stand der Technik} in Introduction
% Self supervised learning (JTrans, PalmTree)
% Same Source policy (Safe)
%  Clap
\section{Methodik}
\subsection{Datensatz}
Im Maschinellen lernen hat der Datensatz bzw. die Trainingsdaten den
größten Einfluss auf die güte des Modells.
% Warum ist die Auswahl des Datensatzes wichtig
% Warum Glibc? 
% Gleicher Standard mit gleicher Semantik unterschiedlich Implementierung
\subsection{Datenpipeline}
% Treesitter erklären
% Source Code information in json datei speichern
% Dann Source code information in Vektor umwandeln
% Modularität -> Vorteile dieses Designs 
\subsection{Stabilität von SentenceTransformer}
% Label Prozess sollte stabil sein bzw. deterministisch, sonst
% kann keine aussage über die Güte der Labels getätig werden
% Tabelle mit Ergebnissen der standardabweichungen

\
\section{Funktionskommentare}
\subsection{Motivation}
% Warum könnten funktionskommentare dafür geignet sein die Semantik einer
% Funktion zu beschreiben
\subsection{Methodik} 
% Probleme beim Parsen, wo sucht man nach Kommentaren?
% Keine einheitliche Konvention
% -> Unterschiedliche Code Base Unterschiedliche Kommentar Konventionen
\section{Code2Vec}
\subsection{Motivation} 
% Warum könnte code2vec semantisch gute Vektoren produzieren
\subsection{Adaption auf C} 
% code2vec erklären
\subsection{Training}
% Ganzes engeneering und pain hinter code2vec
\section{Funktionsnamen}
\subsection{Motivation}
% Motivation warum es gute semantische Vektoren erzeugen konnte
\subsection{Methodik}
% Parsen
% Eigentlich einfach aber wenn man in Zukunft 
% Viele System nahe sprachen dazu nehmen will
% wie Rust, C, Zig, usw. 
% Ist es doch schwieriger
% -> Treesitter
\section{Coddelama-Erklärungen}
\subsection{Motivation}
%Warum LLM's gute Embeddings produzieren könnten.
%Wir erzeugen uns eine zusammenfassung vom code
% "optimale" Kommentare
\subsection{Codellama} 
% Was ist Codellama und warum benutzten wir es?
\subsection{Prompt Engeneering und Temperature}
% Von Chatbot zu relativ deterministischen Modell
% Ergebnisse der Standardabweichung mit Temperatur 0
\section{Ergebnisse}
\subsection{Evaluierung durch Experten}
\subsubsection{Methodik}
% Aufbau des Fragebogens und
% Stichproben Größe, vlt. Vorstellung der Experten
\subsubsection{Auswertung und Ergebnisse}
% Diskussion der Ergebnisse
% Folgerungen das CodeLlamma "gute" Embeddings produziert 
\subsection{Qualitative Evaluierung} 
% t-SNE Plots
% Vielleicht nochmal subsections mit Funktionsname, Funktionskommentare, 
% Funktionserklärung, und Code2Vec Vektoren
% Probleme des jeweiligen Ansatzes mit drei Vektoren
\subsection{Quantitative Evaluierung} 
% Formel um zwei Embedding spaces zu vergleichen
% Formel erklären und rechtfertigen
% Aus Umfrage rechtfertigen Codellama Summaries als gute
% embeddings zu verwenden
\section{Limitation}
\section{Diskussion}
%copy Evaluation
% Zusammenfassung der jeweiligen Resultate
% Funktionnamen -> Nicht geignet, da zu wenig informationen und abkürzungen
% Funktionskommentare -> Je nach Projekt geignet, aber nicht allgemeingültig
%     deswegen eher ungeignet
% Code2Vec -> Kommt nur knapp an mit benutzuten Daten an Names ran also nicht 
% geignet
\section{Fazit}
\section{Results: Comparing natural language supervised methods for creating Rich Binary Labels}
\begin{itemize}
  \item Stabilität von Sentence Transformer
  \item Kommentare von Funktionen um Embeddings zu generieren
  \item Funktionsnamen von Funktionen um Embeddings zu generieren
  \item Code2Vec um Embeddings zu generieren
  \item CodeLlama Erklärungen von Funktionen um Embeddings zu generieren
  \item Evaluierung durch tSNE-Plots
  \item Evaluierung durch Experten
  \item Evaluierung durch Formel
\end{itemize}
$ I_{k}: \mathbf{N} \times \mathbf{N} \times \mathbf{N}^{k} \to [0,1]$
\[ I_{k}(x,i,v) = \begin{cases*} 
      1 & , $\exists j \in \mathbf{N}: x = v_j \land i = j$  \\
      \frac{1}{2} & , $\exists j \in \mathbf{N}: x = v_j \land i \neq j$\\
      0   & , \text{otherwise}
                \end{cases*} \]
$E_k: \nat^k \times \nat^k \to [0,1]$
\[ E_k(u,v) = \frac{1}{G_k} \sum^{k}_{i=1} \frac{I_k(u_i,i,v_i)}{log_2(i+1)}\]
wo $G_k := \sum_{i=1}^{k} \frac{1}{log_2(i+1)}$.\\\\
$CMP_k: \mathbf{R}^{N\times l} \times \mathbf{R}^{N\times l} \times 
\{ \mathbf{R}^l \times \mathbf{R}^{N\times l} \to \mathbf{N}^k \} 
\times \{ \mathcal{P}([0,1]) \to [0,1] \} \to [0,1]$

\[ CMP_k(X,Y,f_k,agg) = agg(\{E_k(f_k(X_{i,j},X),f_k(Y_{i,j},Y)) | j \in \{1,2,3, \dots N\}\})\]


\section{Conclusion}


\section{Notes on form}
\subsection{Formatting} 
This LaTeX template uses the following formatting:
\begin{itemize}
\setlength{\itemsep}{0pt}
	\item font: Linux Libertine O (alternatively: Times New Roman)
	\item font size: 12 pt
	\item left and right margin: 3.5 cm, top and bottom margin: 3 cm
    \item align: left
	\item line spacing: one and a half (alternative: 15 pt line spacing with 12 pt font size)
\end{itemize}

\noindent
When implementing the specifications in Word, it is essential to define style sheets.

\subsection{Citation} 
\label{sec:cit}

The citation method follows the author-year system. Place reference is in the text, footnotes should only be used for explanations and comments. The following notes are taken from the \emph{language} bibliography template from \url{ron.artstein.org}:\newline

\noindent
The \emph{Language} style sheet makes a distinction between two kinds of in-text citations: citing a work and citing an author.
\begin{itemize}
\item Citing a work:
  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parsep}{0pt}
  \item Two authors are joined by an ampersand (\&).
  \item More than two authors are abbreviated with \emph{et al.}
  \item No parentheses are placed around the year (though parentheses
    may contain the whole citation). 
  \end{itemize}
\item Citing an author:
  \begin{itemize}
    \setlength{\itemsep}{0pt}
    \setlength{\parsep}{0pt}
  \item Two authors are joined by \emph{and}.
  \item More than two authors are abbreviated with \emph{and colleagues}.
  \item The year is surrounded by parentheses (with page numbers, if
    present).
  \end{itemize} 
\end{itemize}
To provide for both kinds of citations, \verb+language.bst+ capitalizes on the fact that \verb+natbib+ citation commands come in
two flavors. In a typical style compatible with \verb+natbib+, ordinary commands such as \verb+\citet+ and \verb+\citep+ produce short
citations abbreviated with \emph{et al.}, whereas starred commands such as \verb+\citet*+ and \verb+\citep*+ produce a citation with a
full author list. Since \emph{Language} does not require citations with full authors, the style \verb+language.bst+ repurposes the starred commands to be used for citing the author. The following table shows how the \verb+natbib+ citation commands work with \verb+language.bst+.
\begin{center}
  \begin{tabular}{lll}
    \toprule
    Command & Two authors & More than two authors \\
    \midrule
    \verb+\citet+ & \citet{hale} & \citet{sprouse} \\
    \verb+\citet*+ & \citet*{hale} & \citet*{sprouse} \\
    \addlinespace
    \verb+\citep+ & \citep{hale} & \citep{sprouse} \\
    \verb+\citep*+ & \citep*{hale} & \citep*{sprouse} \\
    \addlinespace
    \verb+\citealt+ & \citealt{hale} & \citealt{sprouse} \\
    \verb+\citealt*+ & \citealt*{hale} & \citealt*{sprouse} \\
    \addlinespace
    \verb+\citealp+ & \citealp{hale} & \citealp{sprouse} \\
    \verb+\citealp*+ & \citealp*{hale} & \citealp*{sprouse} \\
    \addlinespace
    \verb+\citeauthor+ & \citeauthor{hale} & \citeauthor{sprouse} \\
    \verb+\citeauthor*+ & \citeauthor*{hale} & \citeauthor*{sprouse} \\
    \verb+\citefullauthor+ & \citefullauthor{hale} & \citefullauthor{sprouse} \\
    \bottomrule
  \end{tabular}
\end{center}
Authors of \emph{Language} articles would typically use \verb+\citet*+, \verb+\citep+, \verb+\citealt+ and \verb+\citeauthor*+, though they
could use any of the above commands. There is no command for giving a full list of authors.

\section*{Bibliography}
The bibliography of this template includes the references of the \emph{language} stylesheet as a sample bibliography.

\pagebreak

\input{pages/appendix}

\pagebreak

\microtypesetup{protrusion=false}
\listoffigures{}
\listoftables{}
\microtypesetup{protrusion=true}

\clearpage
\printglossaries

\pagebreak

\addcontentsline{toc}{section}{Literatur}
\pagestyle{fancy}

\bibliographystyle{language-dt} %using language.bst
\bibliography{bibliography} %bib-filename

\nocite{*} %List all bib-entries

\end{document}
