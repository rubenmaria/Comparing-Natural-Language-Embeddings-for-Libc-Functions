\documentclass[aspectratio=1610,12pt]{beamer}

\input{beamerPreamble.tex}

\usepackage{hyperref}
\usepackage{tikz}
\usepackage{qrcode}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{svg}
\usepackage{minted}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.symbols}
\usetikzlibrary{shapes.multipart}
\usetikzlibrary{pgfplots.groupplots}
%\usepackage[sfmath]{kpfonts}
%\usetikzlibrary{external}
%\tikzexternalize[prefix=tikz/]
\beamertemplatenavigationsymbolsempty


\author{Ruben Triwari}
\title{Comparing Natural Language Embeddings for Libc Functions as Rich Labels}
\subtitle{Bachelor defense}
\institute{Ludwig Maximilian University Munich}
\date{19, February 2025}

\newcommand*{\qt}[1]{'#1'}
\newcommand*{\p}{^\prime}
\newcommand*{\as}{\;}% "apply-space" for λ-calc
\newcommand*{\la}{\lambda}
\newcommand*{\N}{\mathbb{N}}

\newcommand*{\sps}{\mathcal}
\newcommand*{\tsc}{\textsc}
\newcommand*{\opn}{\operatorname}

\newcommand{\cn}[2]{\textcolor{#1}{#2}}%color next (element)
\newcommand*{\C}{\mathbf{C}}
\definecolor{c1}{RGB}{189, 57, 57}
\definecolor{c2}{RGB}{57, 155, 163}
\definecolor{c3}{RGB}{16, 14, 77}

\definecolor{SkyBlue}{RGB}{135, 206, 235}
\definecolor{CrimsonRed}{RGB}{220, 20, 60}
\definecolor{ForestGreen}{RGB}{34, 139, 34}
\definecolor{Goldenrod}{RGB}{218, 165, 32}
\definecolor{DeepPurple}{RGB}{75, 0, 130}
\definecolor{Coral}{RGB}{255, 127, 80}
\definecolor{Teal}{RGB}{0, 128, 128}
\definecolor{Lavender}{RGB}{230, 230, 250}
\definecolor{Amber}{RGB}{255, 191, 0}
\definecolor{SlateGray}{RGB}{112, 128, 144}

\definecolor{ContrastRed}{RGB}{230, 25, 75}   % Red
\definecolor{ContrastGreen}{RGB}{60, 180, 75}   % Green 
\definecolor{ContrastBlue}{RGB}{0, 130, 200}   % Blue
\definecolor{ContrastOrange}{RGB}{245, 130, 48}  % Orange
\definecolor{ContrastPurple}{RGB}{145, 30, 180}  % Purple
\definecolor{ContrastCyan}{RGB}{70, 240, 240}  % Cyan
\definecolor{ContrastMagenta}{RGB}{240, 50, 230}  % Magenta
\definecolor{ContrastLime}{RGB}{210, 245, 60}  % Lime
\definecolor{ContrastPink}{RGB}{250, 190, 190} % Pink
%\definecolor{c3}{cmyk}{0, 0.7808, 0.4429, 0.1412}
%\definecolor{c4}{gray}{0.6}

\usepackage{mathtools}
\usepackage{stmaryrd}
%\usepackage{newcomputermodern} % Loads unicode-math

\newcommand{\codetosource}[2]{%
  \begin{center}
    \qrcode[height=2cm]{#1}\\
    \vspace{.1cm}
    {#2}
  \end{center}
}
\DeclarePairedDelimiter\catmap{\llbracket}{\rrbracket}
%\DeclarePairedDelimiter\Parens{\lParen}{\rParen}

\makeatletter
\patchcmd{\beamer@sectionintoc}
  {\vfill}
  {\vskip\itemsep\vspace{1cm}}
  {}
  {}
\makeatother  


\usepackage{ellipsis} 
\renewcommand{\ellipsisgap}{0.01em}
\usepackage{xparse}

\newminted{haskell}{mathescape, beameroverlays, escapeinside=||}

\begin{document}
\begin{frame}[plain, noframenumbering]{}
  % this is shown in the beginning of the presentation to keep it exciting
\end{frame}

\begin{frame}
  \vspace{0.4cm}
  \centering
  \includegraphics[scale=0.12]{lmu-logo.png}
  \titlepage
\end{frame}

\begin{frame}[t]{Outline}
  \begin{columns}[c]
    \begin{column}{0.46\textwidth}
      \tableofcontents[hideallsubsections]
    \end{column}
    \begin{column}{0.46\textwidth}
      \begin{center}
        \begin{tikzpicture}[scale=0.7]
          \begin{axis}[
                title={},
                xlabel={},
                ylabel={},
                width=10cm,
                height=7cm,
                xtick=\empty,
                ytick=\empty,
                legend pos=north west,
                scatter/classes={
                  0={mark=*,ContrastBlue},
                  1={mark=*,ContrastRed},
                  2={mark=*,ContrastGreen},
                  3={mark=*,ContrastOrange},
                  4={mark=*,ContrastPurple},
                  5={mark=*,ContrastPink},
                  6={mark=*,ContrastLime},
                  7={mark=*,ContrastCyan},
                  8={mark=*,Teal},
                  9={mark=*,SlateGray}
                }
              ]
              \addplot[
                  scatter,
                  only marks,
                  mark=*,
                  scatter src=explicit symbolic
              ] table [meta index=2] {../data/tsne-plots/prev-data-tsne-summary-tsne-30.dat};
          \end{axis}
        \end{tikzpicture}
      \end{center}
    \end{column}
  \end{columns}
\end{frame}
%-------------------------------------------------------------------------
\section{Motivation \& Research Objective}

\begin{frame}[t]{Motivation}
  \begin{center}
    \begin{tikzpicture}
        \node (doc) [draw, tape, tape bend top=none,fill=gray!10, 
            text width=4cm] {
              \mintinline[breaklines, fontsize=\footnotesize]{python}{
              "I had a lot of fun writing my bachelor thesis!"
              }
        };
        \node (model) [
          draw, rectangle, right= 2cm of doc,
          minimum width= 2.5cm,
          minimum height= 1.5cm,
        ] {NLP-Model};
        \node (vec) [right= 2cm of model] {
          $\begin{pmatrix}
            0.23\\
            0.58\\
            \vdots\\
            0.94
          \end{pmatrix} \in \mathbb{R}^N$
        };
        \draw[->, thick] (doc) -- (model);
        \draw[->, thick] (model) -- (vec);
    \end{tikzpicture}
  \end{center}
  $\rightsquigarrow$  Encoding natural language was a huge 
    factor in recent nlp advancements\\
  $\rightsquigarrow$ Information described as a vector 
  can be used in many downstream task\\
  $\rightsquigarrow$ That motivates 
  encoding binary code and describing them as a vector\\
  $\rightsquigarrow$ That motivates using NLP tools to 
  encode binary code
\end{frame}

\begin{frame}[t]{Motivation}
  \begin{center}
    \begin{tikzpicture}
        \node (doc) [draw, tape, tape bend top=none, fill=gray!10, 
            text width=4.2cm] {
              \begin{minipage}[c]{4.2cm}
                \inputminted[fontsize=\tiny]{C}{summary.c}
              \end{minipage}
        };
        \node (compiler) [
          draw, rectangle, right= 1cm of doc,
          minimum width= 2.5cm,
          minimum height= 1.5cm,
        ] {Compiler};
        \node (asm) [
            draw,
            tape,
            tape bend top=none,
            right= 1cm of compiler,
            fill=gray!10, 
            text width=4cm] {
              \begin{minipage}[c]{4cm}
                \inputminted[fontsize=\tiny]{asm}{factorial.asm}
              \end{minipage}
        };
        \draw[->, thick] (doc) -- (compiler);
        \draw[->, thick] (compiler) -- (asm);
    \end{tikzpicture}
  \end{center}
  $\rightsquigarrow$ Compiler removes important inforamtion 
    in natural language
 % Kompelieren entfernt wichtige Informatiion in 
 % natülicher Sprache die genutz werden könnten
 % -> Aus C Code können Embeddings produziert
\end{frame}

\begin{frame}[t]{Motivation}
  \begin{center}
    \begin{tikzpicture}
        \node (doc) at (0,0) [draw, tape, tape bend top=none, fill=gray!10, 
            text width=4.2cm] {
              \begin{minipage}[c]{4.2cm}
                \inputminted[fontsize=\tiny]{C}{example.c}
              \end{minipage}
        };
        \node (model) at (4.5,0)[
          draw, rectangle,
          minimum width= 2cm,
          minimum height= 1cm,
        ] {NLP-Model};
        \node (vec) at (9,0)[text width=4cm] {
              $ l = \begin{pmatrix}
                l_1 \\ 
                l_2 \\ 
                \vdots \\
                l_N
              \end{pmatrix} \in \mathbb{R}^N
                $
        };
        \draw[->, thick] (doc) -- (model);
        \draw[->, thick] (model) -- (vec);
    \end{tikzpicture}
    \begin{tikzpicture}
        \node (doc) at (0,0) [draw, tape, tape bend top=none, fill=gray!10, 
            text width=2.5cm] {
              \begin{minipage}[c]{2.5cm}
                \inputminted[fontsize=\tiny]{asm}{example.asm}
              \end{minipage}
        };
        \node (model) at (4.5, 0)[
          draw, rectangle,
          minimum width= 2cm,
          minimum height= 1cm,
        ] {Model};
        \node (vec) at (9, 0) {
              $ o = \begin{pmatrix}
                  o_1 \\
                  o_2 \\
                  \vdots \\
                  0_N
                \end{pmatrix} \in \mathbb{R}^N$
        };

      \node (loss) at (7, -2.2) [draw, rectangle] {
            $\mathcal{L}(o,l) \in \mathbb{R}$
        };
        \draw[->, thick] (doc) -- (model);
        \draw[->, thick] (model) -- (vec);
        \draw[->, thick] (vec) to[out=270,in=0] (loss);
        \draw[->, thick] (loss) to[out=180,in=270] (model);
    \end{tikzpicture}
  \end{center}
  % Mit diesen Vektoren aus C-Code
  % kann ein Modell mittels überwachten lernen
  % trainiert werden, welches lernt binary 
  % code in Vektoren umzuwandeln
\end{frame}

\begin{frame}[t]{Research Objectives}
  \begin{itemize}
    \item Compare diffrent approaches generating an Embedding with NLP tools
    \begin{enumerate}
      \item Embed function names with SentenceTransformer
      \item Embed function comments with SentenceTransformer
      \item Embed Code-Llama code summaries with SentenceTransformer
    \end{enumerate}
    \item Compare NLP approach to the existig Code2Vec Model
    \item Propose a new way comparing embedding spaces
  \end{itemize}
  % Verschiedene Methoden zu vergleichen aus C-Quellcode,
  % mithilfe von Werkzeugen aus der natürlichen Sprachverarbeitung,
  % Vektoren zu generieren die den Inhalt 
  % des Quellcodes widerspiegeln.
\end{frame}

\section{Methodology}

\begin{frame}[t, fragile]{Architecture}
  \begin{center}
    \begin{tikzpicture}
        \node (doc) at (-1,0) [draw, rectangle split, 
            rectangle split parts=2,
            fill=gray!10, 
            text width=4.2cm] {
              {\centering \small Source code}
              \nodepart{two} {
                \begin{minipage}[c]{4.2cm}
                  \inputminted[fontsize=\tiny]{C}{example.c}
                \end{minipage}
              }
        };
        \node (parser) at (4.5,0)[
          draw, rectangle,
          minimum width= 2cm,
          minimum height= 1cm,
        ] {Treesitter Parser};
        \node (name) at (9.2,0) [
            draw, rectangle split, rectangle split parts=2,
            fill=gray!10] {
            Source inforamtion
            \nodepart{two}{
              \begin{minipage}[c]{2.2cm}
                \mintinline{json}{"factorial"}
              \end{minipage}
            }
        };
        \node (llama) at (9.2,-3.2) [
            draw, rectangle split, rectangle split parts=2] {
            Code Llama
            \nodepart{two}{
              \begin{minipage}[c]{4.2cm}

                \inputminted[fontsize=\tiny]{Python}{prompt.py}
                %\inputminted[breaklines, fontsize=\tiny]{pyhton}{prompt.py}
              \end{minipage}
            }
        };

        \node (st) at (3.5,-3.2)[
          draw, rectangle,
          minimum width= 2cm,
          minimum height= 1cm,
        ] {SentenceTransformer};
        
        \node (vec) at (-1, -3.2){
            $ l = \begin{pmatrix}
              l_1 \\
              l_2 \\
              \vdots \\
              l_N
            \end{pmatrix}
            \in \mathbb{R}^N$
          };
        
        \draw[->, thick] (doc) -- (parser);
        \draw[->, thick] (parser) -- (name);
        \draw[->, thick] (st) -- (vec);
        \draw[->, thick] (name) -- (llama);
        \draw[->, thick] (name) to[out=270,in=90] (st);
        \draw[->, thick] (llama) -- (st);
    \end{tikzpicture}
  \end{center}
\end{frame}

\section{Results}
\begin{frame}[t]{Expert Survey}
    \begin{figure}
      \centering
      \begin{minipage}{0.45\textwidth}
          \centering
          \includegraphics[scale=0.2]{pictures/survey-example-negative.png}
          \caption{Positve exmaple}
      \end{minipage}
      \begin{minipage}{0.45\textwidth}
          \centering
          \includegraphics[scale=0.2]{survey-example-positive.png}
          \caption{Negative exmaple}
      \end{minipage}
      \begin{table}
        \begin{center}
          \scalebox{0.8} {
            \begin{tabular}{ |p{1.5cm}||p{4.5cm}|p{3.2cm}|p{4cm}|p{1.8cm}|  }
            \hline
            \multicolumn{5}{|c|}{Ergebnisse der Expertenbefragung} \\
            \hline
            Strategie & Code-Llama-Erklärungen & Funktionsnamen & Funktionskommentare & \textit{Code2Vec} \\
            \hline
            Score   & 0.596 & 0.532 & 0.433 & 0.321   \\
            \hline
            \end{tabular}
          }
        \end{center} 
      \end{table}
    \end{figure}
\end{frame}

\begin{frame}[t]{Embeddings space comparison}
  \[
    \texttt{compare}(u,v)_k = 
      \frac{1}{G_k} \sum^{k}_{i=1} 
      \frac{ \texttt{score}_{k}(u_i,i,v)}{log_2(i+1)} 
      \in [0,1]
  \]
  where
  \[ u,v \in \mathbb{N}^k: \text{Neighbor ranking of the same vector in diffrent spaces},\]
  \[
    \texttt{score}_k(l,i,v) = \begin{cases*} 
        1 & , $\exists j \in \mathbb{N}: l = v_j \land i = j$   \\
        \frac{1}{2} & , $\exists j \in \mathbb{N}: l = v_j \land i \neq j$\\
        0   & , \text{otherwise}
      \end{cases*}  \text{  , }
      G_k := \sum_{i=1}^{k} \frac{1}{log_2(i+1)}.
  \]
\end{frame}

\begin{frame}[t]{Embeddings space comparison}
  \[
    \texttt{CMP}(A,B,k) = \frac{1}{N}\sum_{i = 1}^{N}
      \texttt{compare}_k(NN_k(A_i,A),NN_k(B_i, B))
  \]
  where 
  \[
    A,B \in \mathbb{R}^{N\times l}: \text{Embedding space with }
    N \text{ vectors of length} l
  \]
  \[
    \texttt{NN}_k(A_i, A): \text{k nearest neighbors from vector with index i in A}
  \]
  \[
    k \in \mathbb{N}: \text{Amount of vectors we include in one neighborhood relation}
  \]
\end{frame}
\begin{frame}[t]{Embeddings space comparison}
  \begin{center}
    \begin{tikzpicture}
      \begin{axis}[
          xlabel=$k$,
          ylabel=$\text{CMP}(\mathbf{G}{,}\mathbf{D}_i{,}k)$,
          width=0.8\textwidth, 
          height=0.6\textwidth,
          legend style={nodes={scale=0.8, transform shape}}
      ]
      \addplot[ForestGreen, thick] table
        {abb/summary-embeddings-high-comment-embeddings-high-non-empty-compare.dat};
      \addplot[black, thick]
        table {abb/random-compare-plot-487x384.dat};
      \addplot[SkyBlue, thick] 
        table {abb/summary-embeddings-high-name-embeddings-high-compare487.dat};
      \addplot[CrimsonRed, thick] 
        table {abb/summary-embeddings-high-glibc-code2vec-high-compare487.dat};
      \legend{
        Funktionskommentare und Code-Llama-Erklärungen,
        Zufällige Punkte und Code-Llama-Erklärungen,
        Funktionsnamen und Code-Llama-Erklärungen,
        \textit{Code2Vec} und Code-Llama-Erklärungen
      }
      \end{axis}
    \end{tikzpicture}
  \end{center}
\end{frame}
\begin{frame}[t]{Evaluation with T-SNE}
  \begin{figure}
    \begin{center}
      \begin{tikzpicture}
        \begin{groupplot}[
              group style={
                  group size=4 by 1, % 3 plots in 4 row
                  horizontal sep=0.6cm, % Space between plots
                  vertical sep=1cm % Space if there are multiple rows
              },
              width=0.33\textwidth, % Width of each plot
              height=0.33\textwidth, % Height of each plot 
              scatter/classes={
                  0={mark=*,ContrastBlue},
                  1={mark=*,ContrastRed},
                  2={mark=*,ContrastGreen},
                  3={mark=*,ContrastOrange},
                  4={mark=*,ContrastPurple},
                  5={mark=*,ContrastPink},
                  6={mark=*,ContrastLime},
                  7={mark=*,ContrastCyan},
                  8={mark=*,Teal},
                  9={mark=*,SlateGray}
              },
              scatter,
              xlabel={},
              ylabel={},
              xtick=\empty,
              ytick=\empty,
              legend style={
                at={(-1.2,-0.1)},
                legend columns=5,
                fill=none,
                draw=black,
                anchor=north,
                align=center,
                row sep=0.1cm,
                column sep=0.3cm,
                legend cell align=left
              },
          ]
            \nextgroupplot[title={\textit{Code2Vec}}]
            \addplot[scatter, only marks, scatter src=explicit symbolic]
              table[x=x, y=y, meta=label] {abb/prev-data-tsne-code2vec-tsne-30.dat};
            \nextgroupplot[title={Comments}]
            \addplot[scatter, only marks, scatter src=explicit symbolic]
              table[x=x, y=y, meta=label] {abb/prev-data-tsne-comment-tsne-30.dat};
            \nextgroupplot[title={Names}]
            \addplot[scatter, only marks, scatter src=explicit symbolic]
              table[x=x, y=y, meta=label] {abb/prev-data-tsne-name-tsne-30.dat};
            \nextgroupplot[title={Code Llama summaries}]
            \addplot[scatter, only marks, scatter src=explicit symbolic]
              table[x=x, y=y, meta=label] {abb/prev-data-tsne-summary-tsne-30.dat};
            \legend{
              IO, Network, Memory, Threads, Files,
              Processes, Signals, String, Math, 
              Miscellaneous
            }
          \end{groupplot}
      \end{tikzpicture}
    \end{center}
    \caption{
      Depicted are the \textit{t-SNE} output vectors with perplexity $P = 30$.
    }
  \end{figure}
\end{frame}

\section{Limitations}
\begin{frame}{Function names}
  Abbreviations can potentially confuse the SentenceTransformer: \\
  Example function \texttt{lchmod}:
  \begin{align*}
    \text{l} \leftrightarrow \text{link}, \hspace{0.5cm}
    \text{ch} \leftrightarrow \text{change},\hspace{0.5cm}
    \text{mod} \leftrightarrow \text{file mode}.
  \end{align*}
  Nearest neigbors in function space: 
    \[  
      \texttt{lchmod} \leftrightarrow 
      \begin{pmatrix}
        \texttt{lcong48},& \texttt{fchmodat}, &
        \texttt{coshl}, & \texttt{cacoshl} 
      \end{pmatrix}
    \]
  $\rightsquigarrow$ In categories:
    \[  
      \texttt{files} \leftrightarrow 
      \begin{pmatrix}
        \texttt{math},& \texttt{files}, &
        \texttt{math}, & \texttt{math} 
      \end{pmatrix}
    \]
\end{frame}

\begin{frame}{function names}
  Example function \texttt{lchmod}:
  \begin{align*}
    \text{l} \leftrightarrow \text{link}, \hspace{0.5cm}
    \text{ch} \leftrightarrow \text{change},\hspace{0.5cm}
    \text{mod} \leftrightarrow \text{file mode}.
  \end{align*}
  Nearest neigbors in code llama summary space: 
  %fchmodat, fchownat, euidaccess und __file_change_detection_for_stat
  \[
    \texttt{lchmod}
  \]
    \[  
       \leftrightarrow 
      \begin{pmatrix}
        \texttt{fchmodat},& \texttt{fchownat}, &
        \texttt{euidaccess}, & \texttt{\_\_file\_change\_detection\_for\_stat} 
      \end{pmatrix}
    \]
  $\rightsquigarrow$ In categories:
    \[  
      \texttt{files} \leftrightarrow 
      \begin{pmatrix}
        \texttt{files},& \texttt{files}, &
        \texttt{files}, & \texttt{files} 
      \end{pmatrix}
    \]
\end{frame}

\begin{frame}{function comments}
  Comments are not always directly about the code:\\
  Example functions \texttt{rand} and \texttt{rand\_r}:
  \begin{center}
    rand $\leftrightarrow$ Return a random integer between 0
      and RAND\_MAX.\\
    rand\_r  $\leftrightarrow$ This algorithm is mentioned in 
    the ISO C standard, here extended for 32 bits.
  \end{center}
  $\rightsquigarrow$ Cosine distance in comment and 
  llama summary space
    \[
      d_\text{comment}(\texttt{rand}, \texttt{rand\_r}) = 0.8544
      \hspace{0.5cm}
      d_\text{llama}(\texttt{rand}, \texttt{rand\_r}) = 0.2216.
    \]
\end{frame}

\begin{frame}{Code2Vec}
  \begin{itemize}
    \item Also dpendend on the function names in the data set
    \item Bad results could be Explained by:
      \begin{enumerate}
        \item Small data set
        \item C instead of Java
        \item Quality of names in the data set
      \end{enumerate}
  \end{itemize}
\end{frame}

\section{Conclusion \& Future Work}
\begin{frame}{Future Work}
  \begin{itemize}
    \item Code Llama
      \begin{enumerate}
        \item Is it necessary to use a 
          large Model with 70B parameters?
        \item Can Large Language Models 
        produce deterministic Ouput for this application?
        \item Is there a better Prompt?
      \end{enumerate}
    \item Comments
      \begin{enumerate}
        \item Use inline Comments
      \end{enumerate}
  \end{itemize}
\end{frame}

\begin{frame}{Future Work}
    \[
    \texttt{CMP}(A,B,k) = \frac{1}{N}\sum_{i = 1}^{N}
      \texttt{compare}_k(NN_k(A_i,A),NN_k(B_i, B))
    \]
    \[
    \texttt{compare}(u,v)_k = 
      \frac{1}{G_k} \sum^{k}_{i=1} 
      \frac{ \texttt{score}_{k}(u_i,i,v)}{log_2(i+1)} 
      \in [0,1]
    \]
  \begin{itemize}
  \item $\texttt{CMP}(A,B,k) \in [0,1] $ function
    \begin{enumerate}
      \item Is there an optimal value for k?
      \item Is there a better way to generate a neigborhood?\\
        (instead of K-Nearest-Neighbor)
      \item Is there a better way to aggregate the compare functions?
    \end{enumerate}
  \end{itemize}
\end{frame}

\begin{frame}{Conclusion}
  \begin{itemize}
    \item Best strategies ranked: 
    \begin{enumerate}
      \item Code Llama summaries
      \item Function names
      \item Function comments
      \item Code2Vec
    \end{enumerate}
    \item Code Llama summary vectors for 
      C source code downstream tasks
    \item Code Llama summary vectors can now 
      be used to train a Model
  \item $\texttt{CMP}(A,B,k)$ function
    can be used to compare two embedding 
    spaces from the same features Space
  \end{itemize}
\end{frame}

\appendix

\begin{frame}{Discussion}
\end{frame}

\end{document}

\begin{frame}
  \vspace{0.4cm}
  \centering
  \includegraphics[scale=0.12]{lmu-logo.png}
  \titlepage
\end{frame}
